{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Mortgage Prepayment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import time\n",
    "import imp\n",
    "import os\n",
    "import os, os.path\n",
    "import datetime as dt\n",
    "import dateutil.parser as dp\n",
    "import dill\n",
    "import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from csv files in the ./data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # load data from csv files\n",
    "    df = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(\"../30y fixed rate data/fnm/conforming/clean data\"):\n",
    "        for name in files:\n",
    "            file_name = os.path.join(root, name)\n",
    "            if 'pools_part' in file_name:\n",
    "                print(file_name)\n",
    "                if len(df) > 0:\n",
    "                    df = pd.concat([df,pd.read_csv(file_name)])\n",
    "                else:\n",
    "                    df = pd.read_csv(file_name)        \n",
    "\n",
    "    model_name = 'nn-ppm-from-csv.h5' # for saving a model later\n",
    "\n",
    "else:\n",
    "    dill.load_session('notebook_env_all_3_dfs.db')\n",
    "\n",
    "    print('Loaded data as is:')\n",
    "    print('attr_df.shape   = ', attr_df.shape)\n",
    "    print('geo_df.shape    = ', geo_df.shape)\n",
    "    print('seller_df.shape = ', seller_df.shape)\n",
    "\n",
    "    nloans = 250\n",
    "    attr_df = attr_df[attr_df['cnloans']>=nloans]\n",
    "\n",
    "    print('Data size after filtering for >= 250 loans:')\n",
    "    print(f'attr_df.shape = {attr_df.shape}')\n",
    "\n",
    "    geo_df.drop('poolno',axis=1,inplace=True)\n",
    "    df = pd.merge(attr_df,geo_df,on=['cusip','asofdate'],how='left')\n",
    "\n",
    "    seller_df.drop('poolno',axis=1,inplace=True)\n",
    "    df = pd.merge(df,seller_df,on=['cusip','asofdate'],how='left')\n",
    "\n",
    "    df.fillna(0,inplace=True)\n",
    "\n",
    "    model_name = 'nn-ppm-dill-data.h5' # for saving a model later\n",
    "\n",
    "df['Seasonality'] = df['asofdate'].apply(lambda x: int(str(x)[-2:]))\n",
    "\n",
    "print('df.shape = ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all the fields (except cusip and poolsno) are numerical and there are no NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../conv_30yr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12954704 entries, 0 to 29999\n",
      "Data columns (total 111 columns):\n",
      " #   Column              Non-Null Count     Dtype  \n",
      "---  ------              --------------     -----  \n",
      " 0   poolno              12954704 non-null  object \n",
      " 1   asofdate            12954704 non-null  int64  \n",
      " 2   cusip               12954704 non-null  object \n",
      " 3   spread              12954704 non-null  float64\n",
      " 4   SMM                 12954704 non-null  float64\n",
      " 5   DayCount            12954704 non-null  float64\n",
      " 6   OBal                12954704 non-null  float64\n",
      " 7   CBal                12954704 non-null  float64\n",
      " 8   factor              12954704 non-null  float64\n",
      " 9   Coupon              12954704 non-null  float64\n",
      " 10  Wac                 12954704 non-null  float64\n",
      " 11  Wam                 12954704 non-null  float64\n",
      " 12  Age                 12954704 non-null  float64\n",
      " 13  aols                12954704 non-null  float64\n",
      " 14  waols               12954704 non-null  float64\n",
      " 15  ONLoans             12954704 non-null  float64\n",
      " 16  cnloans             12954704 non-null  float64\n",
      " 17  CSato               12954704 non-null  float64\n",
      " 18  oltv                12954704 non-null  float64\n",
      " 19  cltv                12954704 non-null  float64\n",
      " 20  fico                12954704 non-null  float64\n",
      " 21  %CashWindow         12954704 non-null  float64\n",
      " 22  %Majors             12954704 non-null  float64\n",
      " 23  ocltv               12954704 non-null  float64\n",
      " 24  ccltv               12954704 non-null  float64\n",
      " 25  PurpPct_purchase    12954704 non-null  float64\n",
      " 26  PurpPct_refi        12954704 non-null  float64\n",
      " 27  PctChannel_Broker   12954704 non-null  float64\n",
      " 28  PctChannel_Corr     12954704 non-null  float64\n",
      " 29  PctChannel_Retail   12954704 non-null  float64\n",
      " 30  OccPct_investor     12954704 non-null  float64\n",
      " 31  OccPct_owner        12954704 non-null  float64\n",
      " 32  PropUnitsPct_2-4    12954704 non-null  float64\n",
      " 33  pool_issue_month    12954704 non-null  int64  \n",
      " 34  StatePct_AK         12954704 non-null  float64\n",
      " 35  StatePct_AL         12954704 non-null  float64\n",
      " 36  StatePct_AR         12954704 non-null  float64\n",
      " 37  StatePct_AZ         12954704 non-null  float64\n",
      " 38  StatePct_CA         12954704 non-null  float64\n",
      " 39  StatePct_CO         12954704 non-null  float64\n",
      " 40  StatePct_CT         12954704 non-null  float64\n",
      " 41  StatePct_DC         12954704 non-null  float64\n",
      " 42  StatePct_DE         12954704 non-null  float64\n",
      " 43  StatePct_FL         12954704 non-null  float64\n",
      " 44  StatePct_GA         12954704 non-null  float64\n",
      " 45  StatePct_GU         12954704 non-null  float64\n",
      " 46  StatePct_HI         12954704 non-null  float64\n",
      " 47  StatePct_IA         12954704 non-null  float64\n",
      " 48  StatePct_ID         12954704 non-null  float64\n",
      " 49  StatePct_IL         12954704 non-null  float64\n",
      " 50  StatePct_IN         12954704 non-null  float64\n",
      " 51  StatePct_KS         12954704 non-null  float64\n",
      " 52  StatePct_KY         12954704 non-null  float64\n",
      " 53  StatePct_LA         12954704 non-null  float64\n",
      " 54  StatePct_MA         12954704 non-null  float64\n",
      " 55  StatePct_MD         12954704 non-null  float64\n",
      " 56  StatePct_ME         12954704 non-null  float64\n",
      " 57  StatePct_MI         12954704 non-null  float64\n",
      " 58  StatePct_MN         12954704 non-null  float64\n",
      " 59  StatePct_MO         12954704 non-null  float64\n",
      " 60  StatePct_MS         12954704 non-null  float64\n",
      " 61  StatePct_MT         12954704 non-null  float64\n",
      " 62  StatePct_NC         12954704 non-null  float64\n",
      " 63  StatePct_ND         12954704 non-null  float64\n",
      " 64  StatePct_NE         12954704 non-null  float64\n",
      " 65  StatePct_NH         12954704 non-null  float64\n",
      " 66  StatePct_NJ         12954704 non-null  float64\n",
      " 67  StatePct_NM         12954704 non-null  float64\n",
      " 68  StatePct_NV         12954704 non-null  float64\n",
      " 69  StatePct_NY         12954704 non-null  float64\n",
      " 70  StatePct_OH         12954704 non-null  float64\n",
      " 71  StatePct_OK         12954704 non-null  float64\n",
      " 72  StatePct_OR         12954704 non-null  float64\n",
      " 73  StatePct_PA         12954704 non-null  float64\n",
      " 74  StatePct_PR         12954704 non-null  float64\n",
      " 75  StatePct_RI         12954704 non-null  float64\n",
      " 76  StatePct_SC         12954704 non-null  float64\n",
      " 77  StatePct_SD         12954704 non-null  float64\n",
      " 78  StatePct_TN         12954704 non-null  float64\n",
      " 79  StatePct_TX         12954704 non-null  float64\n",
      " 80  StatePct_UT         12954704 non-null  float64\n",
      " 81  StatePct_VA         12954704 non-null  float64\n",
      " 82  StatePct_VI         12954704 non-null  float64\n",
      " 83  StatePct_VT         12954704 non-null  float64\n",
      " 84  StatePct_WA         12954704 non-null  float64\n",
      " 85  StatePct_WI         12954704 non-null  float64\n",
      " 86  StatePct_WV         12954704 non-null  float64\n",
      " 87  StatePct_WY         12954704 non-null  float64\n",
      " 88  SellerPct_AMRHT     12954704 non-null  float64\n",
      " 89  SellerPct_ALS       12954704 non-null  float64\n",
      " 90  SellerPct_CAFULL    12954704 non-null  float64\n",
      " 91  SellerPct_CNTL      12954704 non-null  float64\n",
      " 92  SellerPct_CITIZ     12954704 non-null  float64\n",
      " 93  SellerPct_53        12954704 non-null  float64\n",
      " 94  SellerPct_FIR       12954704 non-null  float64\n",
      " 95  SellerPct_FRDOM     12954704 non-null  float64\n",
      " 96  SellerPct_GUILD     12954704 non-null  float64\n",
      " 97  SellerPct_CHASE     12954704 non-null  float64\n",
      " 98  SellerPct_LLSL      12954704 non-null  float64\n",
      " 99  SellerPct_MATRX     12954704 non-null  float64\n",
      " 100 SellerPct_NCM       12954704 non-null  float64\n",
      " 101 SellerPct_NATIONST  12954704 non-null  float64\n",
      " 102 SellerPct_NRESM     12954704 non-null  float64\n",
      " 103 SellerPct_PNYMAC    12954704 non-null  float64\n",
      " 104 SellerPct_PILOSI    12954704 non-null  float64\n",
      " 105 SellerPct_QUICK     12954704 non-null  float64\n",
      " 106 SellerPct_REG       12954704 non-null  float64\n",
      " 107 SellerPct_RMSC      12954704 non-null  float64\n",
      " 108 SellerPct_UNSHFI    12954704 non-null  float64\n",
      " 109 SellerPct_WFHM      12954704 non-null  float64\n",
      " 110 Seasonality         12954704 non-null  int64  \n",
      "dtypes: float64(106), int64(3), object(2)\n",
      "memory usage: 10.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poolno</th>\n",
       "      <th>asofdate</th>\n",
       "      <th>cusip</th>\n",
       "      <th>spread</th>\n",
       "      <th>SMM</th>\n",
       "      <th>DayCount</th>\n",
       "      <th>OBal</th>\n",
       "      <th>CBal</th>\n",
       "      <th>factor</th>\n",
       "      <th>Coupon</th>\n",
       "      <th>...</th>\n",
       "      <th>SellerPct_NATIONST</th>\n",
       "      <th>SellerPct_NRESM</th>\n",
       "      <th>SellerPct_PNYMAC</th>\n",
       "      <th>SellerPct_PILOSI</th>\n",
       "      <th>SellerPct_QUICK</th>\n",
       "      <th>SellerPct_REG</th>\n",
       "      <th>SellerPct_RMSC</th>\n",
       "      <th>SellerPct_UNSHFI</th>\n",
       "      <th>SellerPct_WFHM</th>\n",
       "      <th>Seasonality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>877118</td>\n",
       "      <td>201012</td>\n",
       "      <td>31409SPB0</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>22.0</td>\n",
       "      <td>58535566.0</td>\n",
       "      <td>58449322.63</td>\n",
       "      <td>99.852665</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>877118</td>\n",
       "      <td>201101</td>\n",
       "      <td>31409SPB0</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58535566.0</td>\n",
       "      <td>58350056.36</td>\n",
       "      <td>99.683082</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>877118</td>\n",
       "      <td>201102</td>\n",
       "      <td>31409SPB0</td>\n",
       "      <td>-66.8</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>19.0</td>\n",
       "      <td>58535566.0</td>\n",
       "      <td>58162116.05</td>\n",
       "      <td>99.362012</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>877118</td>\n",
       "      <td>201103</td>\n",
       "      <td>31409SPB0</td>\n",
       "      <td>-78.7</td>\n",
       "      <td>0.8830</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58535566.0</td>\n",
       "      <td>57564063.94</td>\n",
       "      <td>98.340322</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>877118</td>\n",
       "      <td>201104</td>\n",
       "      <td>31409SPB0</td>\n",
       "      <td>-82.7</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>21.0</td>\n",
       "      <td>58535566.0</td>\n",
       "      <td>56898607.41</td>\n",
       "      <td>97.203480</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   poolno  asofdate      cusip  spread     SMM  DayCount        OBal  \\\n",
       "0  877118    201012  31409SPB0   -19.5  0.0029      22.0  58535566.0   \n",
       "1  877118    201101  31409SPB0   -44.0  0.0247      20.0  58535566.0   \n",
       "2  877118    201102  31409SPB0   -66.8  0.1765      19.0  58535566.0   \n",
       "3  877118    201103  31409SPB0   -78.7  0.8830      23.0  58535566.0   \n",
       "4  877118    201104  31409SPB0   -82.7  1.0095      21.0  58535566.0   \n",
       "\n",
       "          CBal     factor  Coupon  ...  SellerPct_NATIONST  SellerPct_NRESM  \\\n",
       "0  58449322.63  99.852665     3.5  ...                 0.0              0.0   \n",
       "1  58350056.36  99.683082     3.5  ...                 0.0              0.0   \n",
       "2  58162116.05  99.362012     3.5  ...                 0.0              0.0   \n",
       "3  57564063.94  98.340322     3.5  ...                 0.0              0.0   \n",
       "4  56898607.41  97.203480     3.5  ...                 0.0              0.0   \n",
       "\n",
       "   SellerPct_PNYMAC  SellerPct_PILOSI  SellerPct_QUICK  SellerPct_REG  \\\n",
       "0               0.0               0.0              0.0            0.0   \n",
       "1               0.0               0.0              0.0            0.0   \n",
       "2               0.0               0.0              0.0            0.0   \n",
       "3               0.0               0.0              0.0            0.0   \n",
       "4               0.0               0.0              0.0            0.0   \n",
       "\n",
       "   SellerPct_RMSC  SellerPct_UNSHFI  SellerPct_WFHM  Seasonality  \n",
       "0             0.0               0.0             0.0           12  \n",
       "1             0.0               0.0             0.0            1  \n",
       "2             0.0               0.0             0.0            2  \n",
       "3             0.0               0.0             0.0            3  \n",
       "4             0.0               0.0             0.0            4  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('../conv_30yr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape =  (12954704, 111)\n"
     ]
    }
   ],
   "source": [
    "print('df.shape = ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model features selection and defining train/test split\n",
    "\n",
    "* In this section we select which features (columns) are to be used in the model and define a test-train split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = ['asofdate',\n",
    "                 'SMM',\n",
    "                 'spread',\n",
    "                 'DayCount','factor',\n",
    "                 'Wac','Wam','Age','aols','waols','CSato',\n",
    "                 'oltv','cltv','ocltv','ccltv',\n",
    "                 'fico',\n",
    "                 '%CashWindow','%Majors',\n",
    "                 'PurpPct_purchase','PurpPct_refi',\n",
    "                 'PctChannel_Broker','PctChannel_Corr','PctChannel_Retail',\n",
    "                 'OccPct_investor','OccPct_owner','PropUnitsPct_2-4',\n",
    "                 'Seasonality',\n",
    "                \n",
    "                 # features showing geographical composition of a pool\n",
    "                 'StatePct_AK','StatePct_AL','StatePct_AR','StatePct_AZ','StatePct_CA','StatePct_CO','StatePct_CT',\n",
    "                 'StatePct_DC','StatePct_DE','StatePct_FL','StatePct_GA','StatePct_GU','StatePct_HI','StatePct_IA',\n",
    "                 'StatePct_ID','StatePct_IL','StatePct_IN','StatePct_KS','StatePct_KY','StatePct_LA','StatePct_MA',\n",
    "                 'StatePct_MD','StatePct_ME','StatePct_MI','StatePct_MN','StatePct_MO','StatePct_MS','StatePct_MT',\n",
    "                 'StatePct_NC','StatePct_ND','StatePct_NE','StatePct_NH','StatePct_NJ','StatePct_NM','StatePct_NV',\n",
    "                 'StatePct_NY','StatePct_OH','StatePct_OK','StatePct_OR','StatePct_PA','StatePct_PR','StatePct_RI',\n",
    "                 'StatePct_SC','StatePct_SD','StatePct_TN','StatePct_TX','StatePct_UT','StatePct_VA','StatePct_VI',\n",
    "                 'StatePct_VT','StatePct_WA','StatePct_WI','StatePct_WV','StatePct_WY',\n",
    "                 \n",
    "                 # features showing originator composition of a pool\n",
    "                 'SellerPct_AMRHT','SellerPct_ALS','SellerPct_CAFULL','SellerPct_CNTL','SellerPct_CITIZ',\n",
    "                 'SellerPct_53','SellerPct_FIR','SellerPct_FRDOM','SellerPct_GUILD','SellerPct_CHASE',\n",
    "                 'SellerPct_LLSL','SellerPct_MATRX','SellerPct_NCM','SellerPct_NATIONST','SellerPct_NRESM',\n",
    "                 'SellerPct_PNYMAC','SellerPct_PILOSI','SellerPct_QUICK','SellerPct_REG','SellerPct_RMSC',\n",
    "                 'SellerPct_UNSHFI','SellerPct_WFHM']\n",
    "\n",
    "dfm = df[df['cnloans'] >= 250][model_columns]\n",
    "\n",
    "print(f'dfm.shape = {dfm.shape}')\n",
    "\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(dfm['Seasonality'],drop_first=True)\n",
    "dfm = dfm.drop('Seasonality',axis=1)\n",
    "dfm = pd.concat([dfm,dummies],axis=1)\n",
    "\n",
    "print(f'dfm.shape = {dfm.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train/test split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = dfm.drop(['SMM','asofdate'],axis=1)\n",
    "# y = dfm['SMM'].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "data_cutoff = 202010\n",
    "\n",
    "dfm_train = dfm[dfm['asofdate'] <  data_cutoff]\n",
    "dfm_test  = dfm[dfm['asofdate'] >= data_cutoff]\n",
    "\n",
    "X_train = dfm_train.drop(['SMM','asofdate'],axis=1).values\n",
    "y_train = dfm_train['SMM'].values\n",
    "\n",
    "X_test = dfm_test.drop(['SMM','asofdate'],axis=1).values\n",
    "y_test = dfm_test['SMM'].values\n",
    "\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print('\\n')\n",
    "print(f'X_test.shape  = {X_test.shape}')\n",
    "print(f'y_test.shape  = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FF neural-network mortgage prepayment model\n",
    "\n",
    "* In this section we fit the model to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train/test data because buiding a neural net\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input layer / first hidden layer\n",
    "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(1, activation='relu')) # no activation means linear activation a(x)=x\n",
    "#model.add(Dense(1)) # no activation means linear activation a(x)=x\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          batch_size=1024,\n",
    "          epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "losses.plot(figsize=(16,4),grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Validation\n",
    "\n",
    "* to be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valReport(dframe,graphTitle='',lcoup=2.5,hcoup=5,fsize=(24,24)):\n",
    "\n",
    "    ppm_table = dframe[['CBal','model SMM x CBal','SMM x CBal','Coupon','ppmdate']].groupby(['Coupon','ppmdate']).sum()\n",
    "\n",
    "    ppm_table['SMM'] = ppm_table['SMM x CBal']/ppm_table['CBal']\n",
    "    ppm_table['CPR'] = 100*(1-(1-ppm_table['SMM']/100)**12)\n",
    "\n",
    "    ppm_table['model SMM'] = ppm_table['model SMM x CBal']/ppm_table['CBal']\n",
    "    ppm_table['model CPR'] = 100*(1-(1-ppm_table['model SMM']/100)**12)\n",
    "    \n",
    "    fig = plt.figure(figsize=fsize)\n",
    "    \n",
    "    plt.title(graphTitle)\n",
    "\n",
    "    numOfsubgraphs = int((hcoup-lcoup)*2 + 1)\n",
    "\n",
    "    for i in range(numOfsubgraphs):\n",
    "        ax = fig.add_subplot(numOfsubgraphs,1,i+1)\n",
    "        coupon = lcoup + i*0.5\n",
    "        if ('CPR',coupon) in ppm_table.unstack(level=0).columns:\n",
    "            ppm_table.unstack(level=0)[[('CPR',coupon),('model CPR',coupon)]].plot(ax=ax,grid=True)\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_by_coupon(dframe,lcoup=2.5,hcoup=5,col_name='RMSE (CPR)'):\n",
    "    \n",
    "    ppm_table = dframe[['CBal','model SMM x CBal','SMM x CBal','Coupon','ppmdate']].groupby(['Coupon','ppmdate']).sum()\n",
    "\n",
    "    ppm_table['SMM'] = ppm_table['SMM x CBal']/ppm_table['CBal']\n",
    "    ppm_table['CPR'] = 100*(1-(1-ppm_table['SMM']/100)**12)\n",
    "\n",
    "    ppm_table['model SMM'] = ppm_table['model SMM x CBal']/ppm_table['CBal']\n",
    "    ppm_table['model CPR'] = 100*(1-(1-ppm_table['model SMM']/100)**12)\n",
    "    \n",
    "    RMSE_by_coupon = dict()\n",
    "    \n",
    "    for i in range(int((hcoup-lcoup)*2 + 1)):\n",
    "        coupon = lcoup + i*0.5\n",
    "        if ('CPR',coupon) in ppm_table.unstack(level=0).columns:\n",
    "            act_vs_pred = ppm_table.unstack(level=0)[[('CPR',coupon),('model CPR',coupon)]].dropna()\n",
    "            RMSE_by_coupon[coupon] = np.sqrt(mean_squared_error(act_vs_pred[('CPR',coupon)],act_vs_pred[('model CPR'),coupon]))\n",
    "            \n",
    "    RMSE_by_coupon = pd.DataFrame({col_name:list(RMSE_by_coupon.values())},index=RMSE_by_coupon.keys())\n",
    "    RMSE_by_coupon.index.name = 'Coupon'\n",
    "    \n",
    "    return RMSE_by_coupon    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of a neural-network model on a pool by pool basis.\n",
    "\n",
    "* to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "print(f'(test set) mean absolute error       = {np.round(mean_absolute_error(y_test,test_predictions),4)}')\n",
    "print(f'(test set) mean sq root sq error     = {np.round(np.sqrt(mean_squared_error(y_test,test_predictions)),4)}')\n",
    "print(f'(test set) explained variance score  = {np.round(explained_variance_score(y_test,test_predictions),4)}')\n",
    "print('\\n')\n",
    "train_predictions = model.predict(X_train)\n",
    "print(f'(train set) mean absolute error      = {np.round(mean_absolute_error(y_train,train_predictions),4)}')\n",
    "print(f'(train set) mean sq root sq error    = {np.round(np.sqrt(mean_squared_error(y_train,train_predictions)),4)}')\n",
    "print(f'(train set) explained variance score = {np.round(explained_variance_score(y_train,train_predictions),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,test_predictions)\n",
    "plt.xlabel('actuals')\n",
    "plt.ylabel('model predictions')\n",
    "plt.title('actual vs. predicted (test set)')\n",
    "plt.plot(y_test,y_test,'r'); plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train,train_predictions)\n",
    "plt.xlabel('actuals')\n",
    "plt.ylabel('model predictions')\n",
    "plt.title('actual vs. predicted (train set)')\n",
    "plt.plot(y_train,y_train,'r'); plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of a neural network model on large populations of pools/loans\n",
    "\n",
    "* Here we examine model performance on large populations of loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'asofdate' in dfm.columns:\n",
    "    df['model SMM'] = model.predict(scaler.transform(dfm.drop(['SMM','asofdate'],axis=1)))\n",
    "else:\n",
    "    df['model SMM'] = model.predict(scaler.transform(dfm.drop('SMM',axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SMM x CBal'] = df['SMM']*df['CBal']\n",
    "df['model SMM x CBal'] = df['model SMM']*df['CBal']\n",
    "df['ppmdate'] = df['asofdate'].apply(lambda x: dt.date(int(str(x)[:4]),int(str(x)[-2:]),1))\n",
    "df['Vintage'] = df['pool_issue_month'].apply(lambda x: int(str(x)[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valReport(df,graphTitle='2010 thru 2020 Originations by Coupon',fsize=(24,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse_by_coupon(df[df['asofdate']>=data_cutoff],col_name='2010 - 2020 Vintages NN RMSE (CPR)'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valReport(df[df['waols'] <= 200000],graphTitle='2010 thru 2020 Loan Balace Originations by Coupon',fsize=(24,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse_by_coupon(df[(df['asofdate']>=data_cutoff) & (df['waols'] <= 200000)],col_name='200k max NN RMSE (CPR)'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vintage in [2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]:\n",
    "\n",
    "    valReport(df[df['Vintage'] == vintage],graphTitle=f'{vintage} Originations by Coupon',fsize=(24,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vintage in [2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]:\n",
    "\n",
    "    print(np.round(rmse_by_coupon(df[(df['asofdate']>=data_cutoff) & (df['Vintage'] == vintage)],col_name=f'{vintage} NN RMSE (CPR)'),2))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valReport(df[(df['%CashWindow'] == 100) & (df['Vintage'] > 2009)],graphTitle='Cash Window pools prepayments by Coupon',fsize=(24,12),lcoup=2.5,hcoup=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse_by_coupon(df[(df['asofdate']>=data_cutoff) & (df['%CashWindow'] == 100)],col_name='Cash Window - NN RMSE (CPR)'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valReport(df[(df['OccPct_investor'] > 99) & (df['Vintage'] > 2009)],graphTitle='Investor pools prepayments by Coupon',fsize=(24,12),lcoup=3,hcoup=5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse_by_coupon(df[(df['asofdate']>=data_cutoff) & (df['OccPct_investor'] > 99)],col_name='Investor - NN RMSE (CPR)'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valReport(df[(df['PctChannel_Retail'] > 99) & (df['Vintage'] > 2009)],graphTitle='Retail pools prepayments by Coupon',fsize=(24,12),lcoup=3,hcoup=5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(rmse_by_coupon(df[(df['asofdate']>=data_cutoff) & (df['PctChannel_Retail'] > 99)],col_name='Retail - NN RMSE (CPR)'),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the neural network prepayment model in .h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment the line below if you would like to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment the line below if you would like to load the model saved in Git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('nn-ppm-from-csv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section below is still under development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kerastuner as kt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_builder(hp):\n",
    "\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     #input layer / first hidden layer\n",
    "\n",
    "#     first_layer_neurons      = hp.Int('layer_1_units', min_value=32, max_value = 1024, step = 32)\n",
    "#     first_layer_dropout_rate = hp.Float('layer_1_dropout_rate', min_value = 0, max_value = 0.5, step = 0.1)\n",
    "\n",
    "#     model.add(Dense(first_layer_neurons, input_dim=X_train.shape[1], activation='relu'))\n",
    "#     model.add(Dropout(first_layer_dropout_rate))\n",
    "\n",
    "#     # 2nd layer\n",
    "#     second_layer_neurons      = hp.Int('layer_2_units', min_value=128, max_value = 512, step = 32)\n",
    "#     second_layer_dropout_rate = hp.Float('layer_2_dropout_rate', min_value = 0, max_value = 0.5, step = 0.1)\n",
    "\n",
    "#     model.add(Dense(second_layer_neurons, activation='relu'))\n",
    "#     model.add(Dropout(second_layer_dropout_rate))\n",
    "\n",
    "#     # 3rd layer\n",
    "#     third_layer_neurons      = hp.Int('layer_3_units', min_value=64, max_value = 256, step = 32)\n",
    "#     third_layer_dropout_rate = hp.Float('layer_3_dropout_rate', min_value = 0, max_value = 0.5, step = 0.1)\n",
    "\n",
    "#     model.add(Dense(third_layer_neurons, activation='relu'))\n",
    "#     model.add(Dropout(third_layer_dropout_rate))\n",
    "\n",
    "#     # 4th layer\n",
    "#     forth_layer_neurons      = hp.Int('layer_4_units', min_value=32, max_value = 128, step = 32)\n",
    "#     forth_layer_dropout_rate = hp.Float('layer_4_dropout_rate', min_value = 0, max_value = 0.5, step = 0.1)\n",
    "\n",
    "#     model.add(Dense(forth_layer_neurons, activation='relu'))\n",
    "#     model.add(Dropout(forth_layer_dropout_rate))\n",
    "\n",
    "#     #output layer\n",
    "#     model.add(Dense(1, activation='relu')) # relu activation is perfect here, because SMM cannot be negative\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='mse')\n",
    "#     #model.compile(optimizer='rmsprop', loss='mse')    \n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = kt.Hyperband(model_builder,\n",
    "#                      objective='val_loss',\n",
    "#                      max_epochs=10,\n",
    "#                      hyperband_iterations=2,\n",
    "#                      directory=os.path.normpath('C:/'),\n",
    "#                      project_name='nn_ppm_model-' + dt.datetime.now().strftime('%Y-%M-%d-%H-%M-%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(x=X_train,\n",
    "#              y=y_train,\n",
    "#              validation_data=(X_test,y_test),\n",
    "#              batch_size=1024,\n",
    "#              epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
